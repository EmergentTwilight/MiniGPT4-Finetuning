model:
  arch: minigpt4
  model_type: pretrain_vicuna0
  max_txt_len: 500
  end_sym: "</s>"
  low_resource: True
  prompt_template: '[INST] {} [/INST]'
  llama_model: /mnt/data4/home/ziyuan/MiniGPT4-Finetuning/vicuna-7b
  lora_r: 64
  lora_alpha: 16


datasets:
  cc_sbu_align:
    vis_processor:
      train:
        name: "blip2_image_eval"
        image_size: 224
    text_processor:
      train:
        name: "blip_caption"

evaluation_datasets:
  # refcoco:
  #   eval_file_path: /path/to/eval/annotation/path  
  #   img_path: /path/to/eval/image/path      
  #   max_new_tokens: 20
  #   batch_size: 10
  # refcocog:
  #   eval_file_path: /path/to/eval/annotation/path  
  #   img_path: /path/to/eval/image/path    
  #   max_new_tokens: 20
  #   batch_size: 10
  # refcoco+:
  #   eval_file_path: /path/to/eval/annotation/path  
  #   img_path: /path/to/eval/image/path    
  #   max_new_tokens: 20
  #   batch_size: 10
  gqa:
    eval_file_path: /mnt/data4/home/ziyuan/eval_gqa_dataset/testdev_balanced_questions.json
    img_path: /mnt/data4/home/ziyuan/eval_gqa_dataset/gqa_images   
    max_new_tokens: 120
    batch_size: 16
  # okvqa:
  #   eval_file_path: /path/to/eval/annotation/path  
  #   img_path: /path/to/eval/image/path     
  #   max_new_tokens: 20
  #   batch_size: 10
  # vizwiz:
  #   eval_file_path: /path/to/eval/annotation/path  
  #   img_path: /path/to/eval/image/path    
  #   max_new_tokens: 20
  #   batch_size: 10
  # iconvqa:
  #   eval_file_path: /path/to/eval/annotation/path  
  #   img_path: /path/to/eval/image/path    
  #   max_new_tokens: 20
  #   batch_size: 10
  # vsr:
  #   eval_file_path: cambridgeltl/vsr_zeroshot 
  #   img_path: /path/to/eval/image/path    
  #   max_new_tokens: 20
  #   batch_size: 10
  # hm:
  #   eval_file_path: /path/to/eval/annotation/path  
  #   img_path: /path/to/eval/image/path 
  #   max_new_tokens: 20
  #   batch_size: 100

run:
  task: image_text_pretrain
  name: minigpt4_evaluation

  

  

